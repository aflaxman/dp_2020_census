{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun 16 11:04:10 EDT 2019\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "[Errno 2] No such file or directory: 'data'\n",
      "/media/Storage_2/Sam/data\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, pandas as pd\n",
    "import sys\n",
    "import subprocess\n",
    "pd.set_option('display.max_rows', 10)\n",
    "!date\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = \"\"\"SCHEMA_TYPE_CODE\n",
    "SCHEMA_BUILD_ID\n",
    "TABBLKST\n",
    "TABBLKCOU\n",
    "ENUMDIST\n",
    "EUID\n",
    "EPNUM\n",
    "RTYPE\n",
    "QREL\n",
    "QSEX\n",
    "QAGE\n",
    "CENHISP\n",
    "CENRACE\n",
    "QSPANX\n",
    "QRACE1\n",
    "QRACE2\n",
    "QRACE3\n",
    "QRACE4\n",
    "QRACE5\n",
    "QRACE6\n",
    "QRACE7\n",
    "QRACE8\n",
    "CIT\n",
    "\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get State, which has state code s according to STATEFIP_f in EXT1940USCB.sas in https://github.com/uscensusbureau/census2020-das-e2e/tree/master/etl_e2e/ipums_1940\n",
    "#s=25 #this is MA\n",
    "#TL='MA'\n",
    "s=13 #this is GA\n",
    "TL='GA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E25_R1/MDF_PER.txt\n",
      "GA/GA_E25_R1\n",
      "E25_R2/MDF_PER.txt\n",
      "GA/GA_E25_R2\n",
      "E25_R3/MDF_PER.txt\n",
      "GA/GA_E25_R3\n",
      "E25_R4/MDF_PER.txt\n",
      "GA/GA_E25_R4\n",
      "E50_R1/MDF_PER.txt\n",
      "GA/GA_E50_R1\n",
      "E50_R2/MDF_PER.txt\n",
      "GA/GA_E50_R2\n",
      "E50_R3/MDF_PER.txt\n",
      "GA/GA_E50_R3\n",
      "E50_R4/MDF_PER.txt\n",
      "GA/GA_E50_R4\n",
      "E75_R1/MDF_PER.txt\n",
      "GA/GA_E75_R1\n",
      "E75_R2/MDF_PER.txt\n",
      "GA/GA_E75_R2\n",
      "E75_R3/MDF_PER.txt\n",
      "GA/GA_E75_R3\n",
      "E75_R4/MDF_PER.txt\n",
      "GA/GA_E75_R4\n",
      "E1_R1/MDF_PER.txt\n",
      "GA/GA_E1_R1\n",
      "E1_R2/MDF_PER.txt\n",
      "GA/GA_E1_R2\n",
      "E1_R3/MDF_PER.txt\n",
      "GA/GA_E1_R3\n",
      "E1_R4/MDF_PER.txt\n",
      "GA/GA_E1_R4\n",
      "E2_R1/MDF_PER.txt\n",
      "GA/GA_E2_R1\n",
      "E2_R2/MDF_PER.txt\n",
      "GA/GA_E2_R2\n",
      "E2_R3/MDF_PER.txt\n",
      "GA/GA_E2_R3\n",
      "E2_R4/MDF_PER.txt\n",
      "GA/GA_E2_R4\n",
      "E4_R1/MDF_PER.txt\n",
      "GA/GA_E4_R1\n",
      "E4_R2/MDF_PER.txt\n",
      "GA/GA_E4_R2\n",
      "E4_R3/MDF_PER.txt\n",
      "GA/GA_E4_R3\n",
      "E4_R4/MDF_PER.txt\n",
      "GA/GA_E4_R4\n",
      "E6_R1/MDF_PER.txt\n",
      "GA/GA_E6_R1\n",
      "E6_R2/MDF_PER.txt\n",
      "GA/GA_E6_R2\n",
      "E6_R3/MDF_PER.txt\n",
      "GA/GA_E6_R3\n",
      "E6_R4/MDF_PER.txt\n",
      "GA/GA_E6_R4\n",
      "E8_R1/MDF_PER.txt\n",
      "GA/GA_E8_R1\n",
      "E8_R2/MDF_PER.txt\n",
      "GA/GA_E8_R2\n",
      "E8_R3/MDF_PER.txt\n",
      "GA/GA_E8_R3\n",
      "E8_R4/MDF_PER.txt\n",
      "GA/GA_E8_R4\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(['mkdir',TL])\n",
    "for eps in [25,50,75,1,2,4,6,8]:\n",
    "    for run in [1,2,3,4]:\n",
    "        thefile='E%s_R%s/MDF_PER.txt'%(eps,run)\n",
    "        print(thefile)\n",
    "        newfile='%s/%s_E%s_R%s'%(TL,TL,eps,run)\n",
    "        iter_csv = pd.read_csv(thefile, iterator=True, sep='|', header=None,usecols=[2,3,4,7,10,11,12], names=col_names, comment='#',  chunksize=100000)\n",
    "        df = pd.concat([chunk[chunk['TABBLKST'] == s ] for chunk in iter_csv])\n",
    "        print(newfile)\n",
    "        df.to_csv(newfile, sep='\\t')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run(['mkdir','testdir'])\n",
    "eps=25\n",
    "run=1\n",
    "thefile='E%s_R%s/MDF_PER.txt'%(eps,run)\n",
    "newfile='testdir/%s_E%s_R%s'%('test',eps,run)\n",
    "iter_csv = pd.read_csv(thefile, iterator=True, sep='|', header=None,usecols=[2,3,4,7,10,11,12], names=col_names, comment='#',  chunksize=10, nrows=100)\n",
    "df = pd.concat([chunk[chunk['TABBLKST'] == s ] for chunk in iter_csv])\n",
    "df.to_csv(path_or_buf=newfile, sep='\\t')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
